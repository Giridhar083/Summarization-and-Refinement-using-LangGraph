{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import sys\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"fastapi\", \"uvicorn\", \"httpx\", \"langgraph\", \"langchain\"])\n",
        "\n",
        "import uuid\n",
        "from typing import Dict, Any, List, TypedDict, Annotated\n",
        "from fastapi import FastAPI\n",
        "from fastapi.testclient import TestClient\n",
        "from pydantic import BaseModel\n",
        "from langgraph.graph import StateGraph, END"
      ],
      "metadata": {
        "id": "rVW6xWf1rLak"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smart_summarize(text: str) -> str:\n",
        "    if \".\" in text:\n",
        "        return text.split(\".\")[0] + \".\"\n",
        "    return text\n",
        "\n",
        "def smart_refine(text: str) -> str:\n",
        "    fillers = [\"stateful,\", \"multi-actor\", \"expression\", \"application\", \"concept\", \"very\", \"highly\"]\n",
        "    words = text.split()\n",
        "    for filler in fillers:\n",
        "        if filler in text:\n",
        "            return text.replace(filler, \"\").replace(\"  \", \" \").strip()\n",
        "    if len(words) > 3:\n",
        "        return \" \".join(words[:-1]) + \".\"\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "WvtB709trN8I"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    input_text: str\n",
        "    chunks: List[str]\n",
        "    chunk_summaries: List[str]\n",
        "    final_summary: str\n",
        "    length_limit: int\n",
        "    steps: int\n",
        "\n",
        "def split_text(state: AgentState):\n",
        "    text = state.get(\"input_text\", \"\")\n",
        "    chunks = [s.strip() for s in text.split('.') if len(s) > 5]\n",
        "    return {\"chunks\": chunks, \"steps\": 1}\n",
        "\n",
        "def generate_summaries(state: AgentState):\n",
        "    chunks = state.get(\"chunks\", [])\n",
        "    summaries = [smart_summarize(c) for c in chunks]\n",
        "    return {\"chunk_summaries\": summaries, \"steps\": state[\"steps\"] + 1}\n",
        "\n",
        "def merge_summaries(state: AgentState):\n",
        "    summaries = state.get(\"chunk_summaries\", [])\n",
        "    merged = \" \".join(summaries)\n",
        "    return {\"final_summary\": merged, \"steps\": state[\"steps\"] + 1}\n",
        "\n",
        "def refine_summary(state: AgentState):\n",
        "    current = state.get(\"final_summary\", \"\")\n",
        "    refined = smart_refine(current)\n",
        "    return {\"final_summary\": refined, \"steps\": state[\"steps\"] + 1}\n",
        "\n",
        "def length_gate(state: AgentState):\n",
        "    summary = state.get(\"final_summary\", \"\")\n",
        "    limit = state.get(\"length_limit\", 50)\n",
        "    steps = state.get(\"steps\", 0)\n",
        "\n",
        "    print(f\"   [Check] Length: {len(summary)} (Limit: {limit}) -> Content: {summary}\")\n",
        "\n",
        "    if steps > 15:\n",
        "        return END\n",
        "\n",
        "    if len(summary) > limit:\n",
        "        return \"refine\"\n",
        "    return END\n",
        "\n",
        "def build_workflow():\n",
        "    workflow = StateGraph(AgentState)\n",
        "\n",
        "    workflow.add_node(\"split\", split_text)\n",
        "    workflow.add_node(\"summarize\", generate_summaries)\n",
        "    workflow.add_node(\"merge\", merge_summaries)\n",
        "    workflow.add_node(\"refine\", refine_summary)\n",
        "\n",
        "    workflow.set_entry_point(\"split\")\n",
        "    workflow.add_edge(\"split\", \"summarize\")\n",
        "    workflow.add_edge(\"summarize\", \"merge\")\n",
        "    workflow.add_edge(\"merge\", \"refine\")\n",
        "\n",
        "    workflow.add_conditional_edges(\n",
        "        \"refine\",\n",
        "        length_gate,\n",
        "        {\n",
        "            \"refine\": \"refine\",\n",
        "            END: END\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return workflow.compile()\n"
      ],
      "metadata": {
        "id": "G_kL35pTr1ik"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = FastAPI()\n",
        "client = TestClient(app)\n",
        "graphs = {}\n",
        "\n",
        "@app.post(\"/graph/run\")\n",
        "def run_graph(payload: dict):\n",
        "    app_runnable = build_workflow()\n",
        "\n",
        "    inputs = payload.get(\"initial_state\")\n",
        "    if \"steps\" not in inputs:\n",
        "        inputs[\"steps\"] = 0\n",
        "\n",
        "    final_state = app_runnable.invoke(inputs)\n",
        "    return {\n",
        "        \"final_summary\": final_state.get(\"final_summary\"),\n",
        "        \"steps_taken\": final_state.get(\"steps\")\n",
        "    }\n"
      ],
      "metadata": {
        "id": "Vp_JmvqvsB5u"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"LangGraph is a library for building stateful, multi-actor applications with LLMs. It is highly useful.\"\n",
        "\n",
        "payload = {\n",
        "    \"initial_state\": {\n",
        "        \"input_text\": input_text,\n",
        "        \"length_limit\": 65\n",
        "    }\n",
        "}\n",
        "\n",
        "response = client.post(\"/graph/run\", json=payload)\n",
        "result = response.json()\n",
        "\n",
        "print(f\"Original Text: {input_text}\")\n",
        "print(f\"Final Summary: {result['final_summary']}\")\n",
        "print(f\"Steps Taken:   {result['steps_taken']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DCuOBsfshCH",
        "outputId": "6621caf6-f344-4f23-ba99-ed14a65a3fa9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   [Check] Length: 90 (Limit: 65) -> Content: LangGraph is a library for building multi-actor applications with LLMs It is highly useful\n",
            "   [Check] Length: 78 (Limit: 65) -> Content: LangGraph is a library for building applications with LLMs It is highly useful\n",
            "   [Check] Length: 67 (Limit: 65) -> Content: LangGraph is a library for building s with LLMs It is highly useful\n",
            "   [Check] Length: 60 (Limit: 65) -> Content: LangGraph is a library for building s with LLMs It is useful\n",
            "Original Text: LangGraph is a library for building stateful, multi-actor applications with LLMs. It is highly useful.\n",
            "Final Summary: LangGraph is a library for building s with LLMs It is useful\n",
            "Steps Taken:   7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k8MljzMgt4Jb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}